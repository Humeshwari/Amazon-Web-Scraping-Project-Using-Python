{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8cecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8750dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        # Try to find an HTML element with the id \"productTitle\" using the find method of the BeautifulSoup object\n",
    "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "        \n",
    "        # Extract the text of the title element and assign it to a variable\n",
    "        title_value = title.text\n",
    "        \n",
    "        # Remove leading and trailing whitespace from the title text and assign the result to a variable\n",
    "        title_string = title_value.strip()\n",
    "    except AttributeError:\n",
    "        # If the title element can't be found or doesn't have a text attribute, assign an empty string to the title variable\n",
    "        title_string = \"\"\n",
    "    \n",
    "    # Return the title string\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        # Try to find an HTML element with the id \"price_inside_buybox\" using the find method of the BeautifulSoup object\n",
    "        price = soup.find(\"span\", attrs={'id':'price_inside_buybox'}).text\n",
    "        \n",
    "    except:\n",
    "        # If the above step raises an exception, try to find an HTML element with the class \"a-offscreen\"\n",
    "        price = soup.find(\"span\", attrs={'class':'a-offscreen'}).text\n",
    "\n",
    "    # Return the price (or None if no price was found)\n",
    "    return price\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        # Try to find an HTML element with the class \"a-icon a-icon-star a-star-4-5\" using the find method of the BeautifulSoup object\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).text\n",
    "        \n",
    "    except:\n",
    "        # If the above step raises an exception, try to find an HTML element with the same class attribute as in the try block\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).text\n",
    "\n",
    "    # Return the rating (or None if no rating was found)\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        # Try to find an HTML element with the id \"acrCustomerReviewText\" using the find method of the BeautifulSoup object\n",
    "        # Extract the text of the element and strip whitespace from the resulting string\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        # If the above step raises an exception, set review_count to an empty string\n",
    "        review_count = \"\"\n",
    "\n",
    "    # Return the review count (or an empty string if no review count was found)\n",
    "    return review_count\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        # Try to find an HTML element with the id \"availability\" using the find method of the BeautifulSoup object\n",
    "        # Then find the first <span> element within that element and extract the text, removing any leading or trailing whitespace characters\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        # If the above step raises an exception, set available to \"Not Available\"\n",
    "        available = \"Not Available\"\n",
    "\n",
    "    # Return the availability status (or \"Not Available\" if no availability status was found)\n",
    "    return available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed621ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # add your user agent \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    # webpage URL\n",
    "    URL = \"https://www.amazon.com/s?k=laptop&crid=GYZPZZ1UDJU7&sprefix=laptop%2Caps%2C314&ref=nb_sb_noss_2\"\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "\n",
    "    # Store the links\n",
    "    links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "            links_list.append(link.get('href'))\n",
    "\n",
    "    d = {\"title\":[], \"price\":[], \"rating\":[], \"reviews\":[],\"availability\":[]}\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        # Function calls to display all necessary product information\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(get_price(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['reviews'].append(get_review_count(new_soup))\n",
    "        d['availability'].append(get_availability(new_soup))\n",
    "\n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    amazon_df.to_csv(\"amazonweb_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd392a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a268b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
